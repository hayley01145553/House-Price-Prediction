{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/necronia/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from modules.featureEng import *\n",
    "from modules.modelEng import *\n",
    "\n",
    "# to display entire data\n",
    "pd.set_option('display.max_rows', 1500)\n",
    "pd.set_option('display.max_columns', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load Data\n",
    "\"\"\"\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv', index_col='Id')\n",
    "test_df = pd.read_csv('data/test.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature Engineering\n",
    "\"\"\"\n",
    "\n",
    "train_X = train_df.loc[:,train_df.columns!='SalePrice']\n",
    "train_Y = train_df['SalePrice']\n",
    "test_X = test_df.copy()\n",
    "\n",
    "### for testing ###\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#train_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, random_state=777)\n",
    "###################\n",
    "\n",
    "train_X, train_Y, test_X = pre_processing(train_X, train_Y, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ElasticNet Score: (0.13566143092301547) Best params: {'alpha': 0.0005, 'l1_ratio': 0.9, 'max_iter': 10000}\n",
      "ElasticNet(alpha=0.0005, copy_X=True, fit_intercept=True, l1_ratio=0.9,\n",
      "           max_iter=10000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Model: Lasso Score: (0.13570163888119588) Best params: {'alpha': 0.0005, 'normalize': False}\n",
      "Lasso(alpha=0.0005, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Model: Ridge Score: (0.13477452273562035) Best params: {'alpha': 10}\n",
      "Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
      "      random_state=None, solver='auto', tol=0.001)\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestRegressor Score: (0.16165170194209852) Best params: {'max_depth': 5, 'min_samples_leaf': 3, 'n_estimators': 1460}\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=3, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=1460,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVR Score: (0.14622374020802298) Best params: {'C': 10000, 'epsilon': 0.1, 'gamma': 'scale'}\n",
      "SVR(C=10000, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   19.1s finished\n",
      "/Users/necronia/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBRegressor Score: (0.12433001656972636) Best params: {'colsample_bytree': 0.5, 'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 3000, 'refit': True, 'silent': True, 'subsample': 0.9}\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.5, gamma=0,\n",
      "             importance_type='gain', learning_rate=0.05, max_delta_step=0,\n",
      "             max_depth=5, min_child_weight=1, missing=None, n_estimators=3000,\n",
      "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
      "             refit=True, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "             seed=None, silent=True, subsample=0.9, verbosity=1)\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LGBMRegressor Score: (0.13047931947721306) Best params: {'learning_rate': 0.05, 'max_bin': 80, 'n_estimators': 3000, 'num_leave': 1, 'objective': 'regression', 'refit': True}\n",
      "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "              importance_type='split', learning_rate=0.05, max_bin=80,\n",
      "              max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
      "              min_split_gain=0.0, n_estimators=3000, n_jobs=-1, num_leave=1,\n",
      "              num_leaves=31, objective='regression', random_state=None,\n",
      "              refit=True, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/necronia/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([123871.2890255 , 155362.56590145, 183647.52591262, ...,\n",
       "       157219.95063954, 115615.84903664, 224912.64147914])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Predict house price\n",
    "\"\"\"\n",
    "\n",
    "elastic_net = grid_search(train_X, train_Y, ElasticNet())\n",
    "lasso = grid_search(train_X, train_Y, Lasso())\n",
    "ridge = grid_search(train_X, train_Y, Ridge())\n",
    "random_forest = grid_search(train_X, train_Y, RandomForestRegressor())\n",
    "support_vector_regressor = grid_search(train_X, train_Y, SVR())\n",
    "XGBoost = grid_search(train_X, train_Y, xgb.XGBRegressor())\n",
    "light_GBM = grid_search(train_X, train_Y, lgb.LGBMRegressor())\n",
    "\n",
    "stacked_regression = StackingRegressor(\n",
    "        regressors=[elastic_net, lasso, ridge, random_forest, XGBoost, light_GBM],\n",
    "        meta_regressor=support_vector_regressor\n",
    ")\n",
    "\n",
    "stacked_regression.fit(train_X, train_Y)\n",
    "\n",
    "stacked = stacked_regression.predict(test_X)\n",
    "\n",
    "ensembled = np.expm1((0.1 * elastic_net.predict(test_X)) +\n",
    "                     (0.1 * lasso.predict(test_X)) +\n",
    "                     (0.1 * ridge.predict(test_X)) +\n",
    "                     (0.05 * random_forest.predict(test_X)) +\n",
    "                     (0.3 * XGBoost.predict(test_X)) +\n",
    "                     (0.25 * light_GBM.predict(test_X)) +\n",
    "                     (0.1 * stacked))\n",
    "\n",
    "ensembled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for testing ###\n",
    "#RMSE = np.mean((ensembled - test_Y)**2)**(1/2) \n",
    "#print('Score : ' + str(RMSE))\n",
    "###################\n",
    "\n",
    "\"\"\"\n",
    "Export submission data\n",
    "\"\"\"\n",
    "submission = pd.DataFrame({\n",
    "    'Id':test_X.index,\n",
    "    'SalePrice':ensembled\n",
    "})\n",
    "submission.to_csv('data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
